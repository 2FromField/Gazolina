# Gazolina

![Kubernetes](https://img.shields.io/badge/Kubernetes-3069DE?style=for-the-badge&logo=kubernetes&logoColor=white)
![ArgoCD](https://img.shields.io/badge/Argo%20CD-1e0b3e?style=for-the-badge&logo=argo&logoColor=#d16044)
![Airflow](https://img.shields.io/badge/Airflow-017CEE?style=for-the-badge&logo=Apache%20Airflow&logoColor=white)
![Python](https://img.shields.io/badge/Python-FFD43B?style=for-the-badge&logo=python&logoColor=blue)
![Selenium](https://img.shields.io/badge/Selenium-43B02A?style=for-the-badge&logo=Selenium&logoColor=white)
![GCP](https://img.shields.io/badge/Google_Cloud-4285F4?style=for-the-badge&logo=google-cloud&logoColor=white)

Projet visant √† r√©cup√©rer les prix annonc√©s des stations esssences sur diff√©rents carburants dans une zone g√©ographique. Associ√© √† une application streamlit (dashboard) facilitant la prise de d√©cision journali√®re et affichant l'historique des fluctuations.

## BPMN

![Diagramme BPMN](uv_gazolina/BPMN/diagram.svg)

## Source(s) de donn√©es

- MonEssence.fr : https://mon-essence.fr/ville/29383-mauregny-en-haye?q=02820

# Base de donn√©es

## Sch√©ma

-> draw.io A FAIRE

## Type de donn√©es

-> Tables (nom colonne, description, type, valeurs)
| Nom colonne | Description |
| --------------------------------- | --------------------------------------------------: |
| `id` | Identifiant unique de l'insertion |
| `date` | Date du reccueil des donn√©es |
| `code_postale` | Code postal de la requ√™te |
| `carburant` | Type de carburant r√©cup√©r√© |
| `station` | Nom de la station d'essence |
| `ville` | Nom de la ville dans laquelle la station est localis√©e |
| `distance` | Distancedepuis la position g√©olocalis√©e du site |
| `prix` | Prix affich√© en euros (‚Ç¨) du carburant |
| `verif` | V√©rification du prix le jour-m√™me |
| `lien` | Lien du site web de la station |

# Architecture du projet

```
‚îú‚îÄ‚îÄ üìÅ .venv/ üö´ (auto-hidden)
‚îú‚îÄ‚îÄ üìÅ dags/
‚îÇ   ‚îî‚îÄ‚îÄ üêç dag_essence.py
‚îú‚îÄ‚îÄ üìÅ data/
‚îú‚îÄ‚îÄ üìÅ gitops/
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ apps/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ‚öôÔ∏è airflow.yaml
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ‚öôÔ∏è postgresql.yaml
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ‚öôÔ∏è selenium-standalone-chrome.yaml
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ components/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ üìÅ postgresql/
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ ‚öôÔ∏è values.yaml
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ helm/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ üìÅ airflow/
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ üìÅ templates/
‚îÇ   ‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ üìÑ _noop.tpl
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ üìÑ .helmignore
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ ‚öôÔ∏è Chart.yaml
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ ‚öôÔ∏è values.yaml
‚îÇ   ‚îî‚îÄ‚îÄ üìÅ projects/
‚îÇ       ‚îî‚îÄ‚îÄ ‚öôÔ∏è platform-project.yaml
‚îú‚îÄ‚îÄ üìÅ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ __pycache__/ üö´ (auto-hidden)
‚îÇ   ‚îú‚îÄ‚îÄ üêç MonEssence.py
‚îÇ   ‚îú‚îÄ‚îÄ üêç MonEssence_local.py
‚îÇ   ‚îî‚îÄ‚îÄ üêç utils.py
‚îú‚îÄ‚îÄ üìÑ .DS_Store üö´ (auto-hidden)
‚îú‚îÄ‚îÄ üìÑ .python-version üö´ (auto-hidden)
‚îú‚îÄ‚îÄ üìñ README.md
‚îú‚îÄ‚îÄ üêç main.py
‚îú‚îÄ‚îÄ ‚öôÔ∏è pipeline.conf
‚îú‚îÄ‚îÄ ‚öôÔ∏è pyproject.toml
‚îú‚îÄ‚îÄ üìÑ requirements.txt
‚îú‚îÄ‚îÄ ‚öôÔ∏è root-app.yaml
‚îî‚îÄ‚îÄ üîí uv.lock
```

# Services index√©s

## Pr√©-requis

- Installer k8s:

```
sudo apt-get update
sudo apt-get install -y ca-certificates curl apt-transport-https gnupg
sudo mkdir -p /etc/apt/keyrings
curl -fsSL https://pkgs.k8s.io/core:/stable:/v1.30/deb/Release.key \
  | sudo gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg
echo 'deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.30/deb/ /' \
  | sudo tee /etc/apt/sources.list.d/kubernetes.list
sudo apt-get update && sudo apt-get install -y kubectl
kubectl version --client
```

- Installer helm:

```
curl -fsSL https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash
helm version
```

- Installer un driver Docker:

```
sudo apt-get update
sudo apt-get install -y ca-certificates curl gnupg

# Repository Docker officiel
sudo install -m 0755 -d /etc/apt/keyrings
curl -fsSL https://download.docker.com/linux/debian/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg
echo \
  "deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] \
  https://download.docker.com/linux/debian \
  $(. /etc/os-release && echo $VERSION_CODENAME) stable" \
| sudo tee /etc/apt/sources.list.d/docker.list > /dev/null

sudo apt-get update
sudo apt-get install -y docker-ce docker-ce-cli containerd.io

# d√©marrer et activer
sudo systemctl enable --now docker

# Activer le sudo mode
sudo usermod -aG docker $USER
newgrp docker
docker info
```

- Cluster local minikube (sans GKE)

```
curl -LO https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64
sudo install minikube-linux-amd64 /usr/local/bin/minikube

# Lancer minikube avec le driver docker
minikube start --driver=docker

# V√©rifier les noeuds et pods
kubectl get nodes
kubectl -n kube-system get pods
```

## ArgoCD

- Cr√©er le namespace & installer le manifest

```
kubectl create namespace argocd
kubectl -n argocd apply -f https://raw.githubusercontent.com/argoproj/argo-cd/stable/manifests/install.yaml
```

- Acc√©der √† l'UI par port-forward (sur la VM): `kubectl -n argocd port-forward svc/argocd-server 8080:443`

- Cr√©er un tunnel pour acc√©der √† l'UI sur votre ordinateur (sur le terminal du PC):

```
gcloud auth login # s'authentifier
gcloud config set project gazolina # setup le projet

# Ouvrir le tunnel
gcloud compute ssh vm-gazolina \
  --project gazolina \
  --zone europe-west1-b \
  -- -N -L 8443:127.0.0.1:8080
```

- S'authentifier avec l'utilisateur "admin" et le password cr√©√©: `kubectl -n argocd get secret argocd-initial-admin-secret -o jsonpath='{.data.password}' | base64 -d; echo`

## Postgresql

1. Cr√©ation des fichiers `gitops/apps/postgresql.yaml` & `gitops/components/postgresql/values.yaml`

2. Mettre √† jour le fichier `gitops/apps/projects/platform-project.yaml` avec le nouveau chart destin√© √† la base de donn√©es PostgreSQL

## Apps-of-app

1. Mettre en place l'architecture:

- gitops/
  - apps/ # ‚Üê le root va pointer ici
    - airflow.yaml # Application Argo CD pour Airflow
    - postgresql.yaml # Application pour la DB PostgreSQL
    - (autres-apps‚Ä¶).yaml
  - projects/
    platform-project.yaml # AppProject (bonnes pratiques)
  - values/
    - airflow/values.yaml # tes values Helm Airflow
- root-app.yaml

2. Cr√©er les fichiers `platform-project.yaml` & `root-app.yaml`

3. Accorder l'acc√®s en SSH √† ArgoCD:

- Pr√©parer une deploy key: `ssh-keygen -t ed25519 -N "" -f ~/.ssh/id_ed25519_argocd -C "argocd-repo"`
- R√©cup√©rer la cl√©: `cat ~/.ssh/id_ed25519_argocd.pub`
- G√©n√©rer le secreta avec known_hosts: `ssh-keyscan github.com > /tmp/known_hosts`
- Cr√©er le Secret repository dans argocd:

```
kubectl -n argocd create secret generic repo-gazolina \
  --from-literal=url='git@github.com:2FromField/Gazolina.git' \
  --from-file=sshPrivateKey="$HOME/.ssh/id_ed25519_argocd" \
  --from-file=sshKnownHosts=/tmp/known_hosts

kubectl -n argocd label secret repo-gazolina \
  argocd.argoproj.io/secret-type=repository --overwrite
```

- V√©rification:

```
# Pr√©sence de la cl√© priv√©e:
kubectl -n argocd get secret repo-gazolina -o jsonpath='{.data.sshPrivateKey}' | base64 -d | head -n3
```

3. Cr√©er le projet "platform": `kubectl apply -n argocd -f https://raw.githubusercontent.com/2FromField/Gazolina/main/uv_gazolina/gitops/projects/platform-project.yaml`

4. Cr√©er le service "root": `kubectl apply -n argocd -f https://raw.githubusercontent.com/2FromField/Gazolina/main/uv_gazolina/root-app.yaml` & rafraichir: `kubectl -n argocd patch application root   --type merge -p '{"metadata":{"annotations":{"argocd.argoproj.io/refresh":"hard"}}}'`

5. V√©rifier que le projet "platform" a √©t√© cr√©√©: `kubectl -n argocd get appproject`

## Airflow

### Installation

- Pr√©parer l'acc√®s Git pour la git-sync (via SSH):

```
# G√©n√®re une cl√© SANS passphrase (ou r√©utilise ta deploy-key GitHub)
ssh-keygen -t ed25519 -N "" -f ./id_ed25519 -C "airflow@cluster"
cat ./id_ed25519.pub

# known_hosts GitHub (ed25519) :
ssh-keyscan github.com > ./known_hosts
```

- Cr√©er le namespace pour Airflow: `kubectl create namespace airflow`

- Cr√©er les secrets n√©cessaires:

```
# Cl√© SSH du repo GitHub
kubectl -n airflow create secret generic airflow-ssh-secret \
  --from-file=gitSshKey=./id_ed25519 \
  --from-file=known_hosts=./known_hosts

# Cl√© Fernet
FERNET_KEY=$(head -c 32 /dev/urandom | base64 | tr '+/' '-_' | tr -d '\n')
kubectl -n airflow create secret generic airflow-fernet-key \
  --from-literal=airflow-fernet-key="$FERNET_KEY"

# Cl√© secret Flask du webserver
kubectl -n airflow create secret generic airflow-webserver-secret-key \
  --from-literal=webserver-secret-key='Yx3tYqQZfHn9v2S5pL7T1dK0wR8uM6cN4bA2fG1hJ0qZ' \
  --dry-run=client -o yaml | kubectl apply -f -

# Relancer les pods
kubectl -n airflow rollout restart deploy/airflow-webserver
kubectl -n airflow rollout restart statefulset/airflow-scheduler
```

- Supprimer le service et le relancer:

```
kubectl -n argocd delete application airflow
```

- G√©n√©rer le fichier de d√©pendances 'requirements.txt': `uv pip compile uv_gazolina/pyproject.toml -o uv_gazolina/requirements.txt`

- (Sp√©cificit√© √† MongoDB) Ajouter l'adresse IP de la VM pour dans le 'Network Access':

```
kubectl -n airflow run curlip --rm -it --image=curlimages/curl --restart=Never -- \
  curl -s https://ifconfig.me
```

---

V√©rifications:

- Image PostgreSQL (devant √™tre: "docker.io/bitnami/postgresql:16"):

```
kubectl -n airflow get statefulset airflow-postgresql \
  -o jsonpath='{.spec.template.spec.containers[0].image}{"\n"}'
```

- V√©rifier la Job migration:

```
kubectl -n airflow get jobs,pods | grep -i migrate || true
MIGPOD=$(kubectl -n airflow get pod -l job-name=airflow-migrate-database-job -o jsonpath='{.items[0].metadata.name}' 2>/dev/null) || true
[ -n "$MIGPOD" ] && kubectl -n airflow logs "$MIGPOD" --tail=200 || echo "Pas de pod de migration trouv√©"
```

Si la sortie retourne "Pas de pod de migration trouv√©", alors il faut cr√©er une Job 'one-shot' faisant un `airflow db upgrade`:

```
cat <<'YAML' | kubectl -n airflow apply -f -
apiVersion: batch/v1
kind: Job
metadata:
  name: airflow-db-migrate
spec:
  backoffLimit: 2
  template:
    spec:
      restartPolicy: OnFailure
      containers:
      - name: migrate
        image: apache/airflow:2.9.3
        command: ["bash","-lc","airflow db migrate"]
        env:
          - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN
            value: "postgresql+psycopg2://airflow:airflow@postgresql.database.svc.cluster.local:5432/airflow"
YAML

# Suivre la migration
kubectl -n airflow logs -f job/airflow-db-migrate
```

### Configuration des cr√©dentials

1. Cr√©er un fichier `uv_gazolina/pipeline.conf` contenant les credentials

2. Installer Homebrew: `/bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"`

3. Installer age & SOPS sur MacOS:

```
brew update
brew install age sops

# Confirmer l'installation en affichant les versions
age --version
sops --version
```

3. G√©n√©rer une cl√© de chiffrage SOPS (+ age):

```
mkdir -p ~/.config/sops/age
age-keygen -o ~/.config/sops/age/keys.txt
PUB=$(age-keygen -y ~/.config/sops/age/keys.txt)
echo "$PUB"
```

4. Chiffrer le fichier 'pipeline.conf' en 'pipeline.conf.enc' avec SOPS et la cl√© de chiffrement:

```
sops --encrypt --age "$PUB" uv_gazolina/pipeline.conf > uv_gazolina/pipeline.conf.enc
```

5. Cr√©er le manifest de Secret afin de cr√©er un Secret k8s pour ArgoCD:

```
cat > uv_gazolina/gitops/secrets/mongo-pipeline.yaml <<'YAML'
apiVersion: v1
kind: Secret
metadata:
  name: mongo-pipeline
  namespace: airflow
type: Opaque
stringData:
  MONGO_URI: mongodb+srv://user:pass@host/db
  MONGO_USER: user
  MONGO_PASS: pass
YAML
```

6. Chiffrer localement avec SOPS: `sops --encrypt --age "$PUB" -i uv_gazolina/gitops/secrets/mongo-pipeline.yaml`

7. Copier la cl√© priv√©e age du local vers la VM:

```
mkdir -p ~/.config/sops/age
cat > ~/.config/sops/age/keys.txt <<'EOF'
# colle ici TOUT le contenu affich√© sur ton Mac,
# y compris les lignes "# public key: ..." et la ligne AGE-SECRET-KEY-1...
EOF
```

8. Cr√©er le secret dans 'argocd':

```
kubectl -n argocd create secret generic sops-age \
  --from-file=age.agekey=$HOME/.config/sops/age/keys.txt \
  --dry-run=client -o yaml | kubectl apply -f -
```

9. Cr√©er le ConfigMap du plugin CMP:

```
cat <<'YAML' | kubectl apply -f -
apiVersion: v1
kind: ConfigMap
metadata:
  name: argocd-cmp-cm
  namespace: argocd
data:
  sops-plugin.yaml: |
    apiVersion: argoproj.io/v1alpha1
    kind: ConfigManagementPlugin
    metadata:
      name: sops
    spec:
      version: v1.0
      # Autorise explicitement ton repo (sinon: "plugin ... not supporting the given repository")
      allow:
        repos:
          - https://github.com/2FromField/Gazolina.git
      generate:
        command: [bash, -lc]
        args:
          - |
            set -euo pipefail
            # D√©chiffre chaque YAML s'il est chiffr√© SOPS, sinon le laisse tel quel, puis agr√®ge
            files=$(find . -type f \( -name "*.yaml" -o -name "*.yml" \));
            for f in $files; do
              if sops -d "$f" >/dev/null 2>&1; then sops -d "$f"; else cat "$f"; fi
            done | yq -s cat
YAML
```

10. Monter le secret dans 'argocd-repo-sercer' et red√©marrer:

```
kubectl -n argocd create secret generic sops-age \
  --from-file=age.agekey=$HOME/.config/sops/age/keys.txt \
  --dry-run=client -o yaml | kubectl apply -f -

kubectl -n argocd patch deploy argocd-repo-server --type merge -p '{
  "spec":{"template":{"spec":{
    "volumes":[{"name":"sops-age","secret":{"secretName":"sops-age"}}],
    "containers":[{"name":"argocd-repo-server",
      "volumeMounts":[{"name":"sops-age","mountPath":"/sops"}],
      "env":[{"name":"SOPS_AGE_KEY_FILE","value":"/sops/age.agekey"}]
    }]
  }}}}'
kubectl -n argocd rollout restart deploy/argocd-repo-server
```

11. Ajouter un Config Management Plugin permettant √† ArgoCD de d√©chirer les fichier .yaml SOPS

```
kubectl -n argocd patch configmap argocd-cm --type merge -p '{
  "data": {
    "configManagementPlugins": "- name: sops\n  generate:\n    command: [\"bash\",\"-lc\"]\n    args: [\"set -euo pipefail; files=$(find . -type f \\( -name \\\"*.yaml\\\" -o -name \\\"*.yml\\\" \\)); for f in $files; do if sops -d $f >/dev/null 2>&1; then sops -d $f; else cat $f; fi; done | yq -s cat\"]\n"
  }
}'
kubectl -n argocd rollout restart deploy/argocd-repo-server
```

#### Commandes utiles k8s

| Commade                            |                             Description |
| ---------------------------------- | --------------------------------------: |
| `kubectl get svc --all-namespaces` |    Afficher tous les services install√©s |
| `kubectl get pods -n airflow`      | Afficher les pods d'un namespace pr√©cis |

## UV

### Installation

1. Installation des UV pour Linux : `curl -LsSf https://astral.sh/uv/install.sh | sudo sh`
2. Ajouter UV dans le $PATH : `source $HOME/.local/bin/env`
3. V√©rifier l'installation : `uv --version`

### Notes utiles

1. Cr√©er et nommer le projet : `uv init $UV_PROJECT_NAME`
2. Naviguer dans le projet : `cd $UV_PROJECT_NAME`
3. Utiliser UV : `uv add $PACKAGE`

| Commade                           |                                         Description |
| --------------------------------- | --------------------------------------------------: |
| `uv add $PACKAGE`                 |                Ajouter une ou plusieurs d√©pendances |
| `uv add $PACKAGE=2.0.2`           |    Ajouter une d√©pendance sous une certaine version |
| `uv remove $PACKAGE`              |                            Supprimer une d√©pendance |
| `uv python list --only-installed` | Afficher la liste des d√©pendances et leurs versions |
| `uv run $PYTHON_FILENAME.py`      |                 Ex√©cuter des scripts python avec UV |
| `uv export -o requirements.txt`   |                 G√©n√©rer le fichier requirements.txt |

# Configuration de la VM GCP

## Cr√©ation

- R√©gion: europe-west1 (Belgique)
- Zone: europe-west1-b
- Type: e2-medium (2 vCPU, 1 coeur(s), 4 Go de m√©moire)

OU </br>

```
gcloud compute instances create vm-gazolina \
  --project gazolina \
  --zone europe-west1-b \
  --machine-type=e2-medium \
  --image-family=debian-12 \
  --image-project=debian-cloud
```

## Supprimer

Supprimer l'instance et son disque boot, puis recr√©er une VM neuve: </br>

```
gcloud compute instances delete vm-gazolina \
  --project gazolina \
  --zone europe-west1-b \
  --delete-disks=all
```

## Connexion depuis VSCode

1. V√©rifier l'identifiant du compte GCP: `gcloud auth list`

- Si l'adresse mail n'est pas celle du compte, l'ajouter: `gcloud auth login` et suivre les indication de la page web

2. V√©rifier que l'on cible le bon projet contenant notre VM: `gcloud config get-value project` (l'identifiant se trouve sur GCP lors du choix du projet)

- Si ce n'est pas le bon projet, red√©finir la target: `gcloud config set project gazolina`

3. V√©rifier que la vm est bien pr√©sente dans le projet:

```
gcloud compute instances list --project gazolina \
  --filter='name=("vm_gazolina")' \
  --format='table(project, name, zone, status, networkInterfaces[].accessConfigs[].natIP)'
```

4. Installation des composants GCP cloud: `gcloud components update`

5. S'y connecter:

```
gcloud compute ssh vm-gazolina \
  --project gazolina \
  --zone europe-west1-b
```

## Modifier la VM

- Augmenter la taille du disque boot:

```
gcloud compute disks resize vm-gazolina \
  --project gazolina \
  --zone europe-west1-b \
  --size 60GB
```

- Modifier l'espace de stockage du `sda1`:

1. Rep√©rer la partition14: `sudo parted -m /dev/sda unit s print`
2. Redimensionner le disque au maximum:

```
sudo parted /dev/sda ---pretend-input-tty <<'EOF'
unit s
print
resizepart 1 100%
Yes
quit
EOF
```

3. Etendre le syst√®me de fichiers: `sudo resize2fs /dev/sda1`
4. Afficher les espaces de stockages: `df -h`

## Recr√©er le cluster minikube de z√©ro

```
# 1. Tuer le cluster minikube
minikube delete --all --purge || true
docker rm -f minikube 2>/dev/null || true

# 2. Nettoyage r√©seau/cache
docker network prune -f
sudo systemctl restart docker

# 3. Configurer le nouveau cluster
minikube config set driver docker
minikube config set cpus 4
minikube config set memory 8192
minikube config set disk-size 20g

minikube start --kubernetes-version=v1.30.0 --delete-on-failure -v=1
```
